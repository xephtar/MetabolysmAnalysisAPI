{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68dd0672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and load the spacy model\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "\n",
    "nlp=spacy.blank(\"en\") \n",
    "\n",
    "# Getting the ner component\n",
    "ner=nlp.add_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c22830f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New label to add\n",
    "LABEL = \"FOOD\"\n",
    "\n",
    "# Training examples in the required format\n",
    "TRAIN_DATA =[ (\"Pizza is a common fast food.\", {\"entities\": [(0, 5, \"FOOD\")]}),\n",
    "              (\"Pasta is an italian recipe\", {\"entities\": [(0, 5, \"FOOD\")]}),\n",
    "              (\"China's noodles are very famous\", {\"entities\": [(8,14, \"FOOD\")]}),\n",
    "              (\"Shrimps are famous in China too\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Lasagna is another classic of Italy\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Sushi is extemely famous and expensive Japanese dish\", {\"entities\": [(0,5, \"FOOD\")]}),\n",
    "              (\"Unagi is a famous seafood of Japan\", {\"entities\": [(0,5, \"FOOD\")]}),\n",
    "              (\"Tempura , Soba are other famous dishes of Japan\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Udon is a healthy type of noodles\", {\"entities\": [(0,4, \"ORG\")]}),\n",
    "              (\"Yogurt is a healthy type of food\", {\"entities\": [(0,6, \"FOOD\")]}),\n",
    "              (\"Chocolate soufflé is extremely famous french cuisine\", {\"entities\": [(0,17, \"FOOD\")]}),\n",
    "              (\"Flamiche is french pastry\", {\"entities\": [(0,8, \"FOOD\")]}),\n",
    "              (\"Burgers are the most commonly consumed fastfood\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Burgers are the most commonly consumed fastfood\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Frenchfries are considered too oily\", {\"entities\": [(0,11, \"FOOD\")]})\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e46b9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Chocolate soufflé is extremely famous french cuisine'\n",
      "  {'entities': [(0, 17, 'FOOD')]}]\n",
      " ['Burgers are the most commonly consumed fastfood'\n",
      "  {'entities': [(0, 7, 'FOOD')]}]\n",
      " ['Lasagna is another classic of Italy' {'entities': [(0, 7, 'FOOD')]}]\n",
      " ['Shrimps are famous in China too' {'entities': [(0, 7, 'FOOD')]}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omerfaruk.davarci/Documents/MetabolysmAnalysisAPI/venv/lib/python3.8/site-packages/spacy/training/iob_utils.py:139: UserWarning: [W030] Some entities could not be aligned in the text \"China's noodles are very famous\" with entities \"[(8, 14, 'FOOD')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<thinc.optimizers.Optimizer at 0x127877540>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "import numpy as np\n",
    "rs = ShuffleSplit(n_splits=1, test_size=.25, random_state=57)\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "for train_index, test_index in rs.split(TRAIN_DATA):\n",
    "    train = np.array(TRAIN_DATA)[train_index.astype(int)]\n",
    "    test = np.array(TRAIN_DATA)[test_index.astype(int)]\n",
    "\n",
    "print(test)\n",
    "    \n",
    "examples = []\n",
    "for text, annots in train:\n",
    "    examples.append(Example.from_dict(nlp.make_doc(text), annots))\n",
    "nlp.initialize(lambda: examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47c5706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new label to ner\n",
    "ner.add_label(LABEL)\n",
    "\n",
    "# Resume training\n",
    "optimizer = nlp.resume_training()\n",
    "move_names = list(ner.move_names)\n",
    "\n",
    "# List of pipes you want to train\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "\n",
    "# List of pipes which should remain unaffected in training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53505594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3.022743818141439e-06}\n",
      "Losses {'ner': 3.022745126082262e-06}\n",
      "Losses {'ner': 3.022821100921677e-06}\n",
      "Losses {'ner': 3.0287262932085724e-06}\n",
      "Losses {'ner': 3.0386742307933816e-06}\n",
      "Losses {'ner': 3.0386754426287986e-06}\n",
      "Losses {'ner': 3.03867752197488e-06}\n",
      "Losses {'ner': 3.0388024391458863e-06}\n",
      "Losses {'ner': 3.0388024400146825e-06}\n",
      "Losses {'ner': 9.247937721471119e-07}\n",
      "Losses {'ner': 9.247939770917272e-07}\n",
      "Losses {'ner': 9.247987497827011e-07}\n",
      "Losses {'ner': 9.248718119900304e-07}\n",
      "Losses {'ner': 9.248718121148857e-07}\n",
      "Losses {'ner': 1.6757339259980018e-06}\n",
      "Losses {'ner': 1.691859147311737e-06}\n",
      "Losses {'ner': 1.8879322359639247e-06}\n",
      "Losses {'ner': 1.8879322377340774e-06}\n",
      "Losses {'ner': 1.8879379636695022e-06}\n",
      "Losses {'ner': 1.89294355833425e-06}\n",
      "Losses {'ner': 7.404015710911418e-13}\n",
      "Losses {'ner': 4.049533900257057e-06}\n",
      "Losses {'ner': 4.124678924683233e-06}\n",
      "Losses {'ner': 4.124681135122588e-06}\n",
      "Losses {'ner': 4.125113349406199e-06}\n",
      "Losses {'ner': 4.125113359289221e-06}\n",
      "Losses {'ner': 4.1251138637230295e-06}\n",
      "Losses {'ner': 4.125117118125692e-06}\n",
      "Losses {'ner': 4.125128812784778e-06}\n",
      "Losses {'ner': 0.0038510214754882578}\n",
      "Losses {'ner': 0.0038510215090650605}\n",
      "Losses {'ner': 1.880032324428517e-11}\n",
      "Losses {'ner': 5.944714578767493e-10}\n",
      "Losses {'ner': 5.986480082435839e-10}\n",
      "Losses {'ner': 1.2204216968234975e-09}\n",
      "Losses {'ner': 1.2279792445773188e-09}\n",
      "Losses {'ner': 2.310294589833732e-08}\n",
      "Losses {'ner': 2.39466719605291e-08}\n",
      "Losses {'ner': 2.3946703338231006e-08}\n",
      "Losses {'ner': 2.3953061509517703e-08}\n",
      "Losses {'ner': 2.4216552585512376e-08}\n",
      "Losses {'ner': 2.4216561771283817e-08}\n",
      "Losses {'ner': 1.0758309509449301e-16}\n",
      "Losses {'ner': 1.0818846736734157e-16}\n",
      "Losses {'ner': 2.2982321300714084e-15}\n",
      "Losses {'ner': 1.7658299710664775e-14}\n",
      "Losses {'ner': 1.9963661498603084e-09}\n",
      "Losses {'ner': 1.9964264839801424e-09}\n",
      "Losses {'ner': 1.9964420993086946e-09}\n",
      "Losses {'ner': 1.997331571209334e-09}\n",
      "Losses {'ner': 2.0061267701339436e-09}\n",
      "Losses {'ner': 2.2947600546721908e-09}\n",
      "Losses {'ner': 2.295063273519039e-09}\n",
      "Losses {'ner': 1.729948235733603e-06}\n",
      "Losses {'ner': 1.7299483316943525e-06}\n",
      "Losses {'ner': 1.7299494172713165e-06}\n",
      "Losses {'ner': 1.7299494174587079e-06}\n",
      "Losses {'ner': 0.0026594850687315045}\n",
      "Losses {'ner': 0.0026594850687315067}\n",
      "Losses {'ner': 0.002681232743033849}\n",
      "Losses {'ner': 0.0026812420123551593}\n",
      "Losses {'ner': 0.0026812442854300014}\n",
      "Losses {'ner': 0.0026812442858871063}\n",
      "Losses {'ner': 0.0026812442931791755}\n",
      "Losses {'ner': 1.3108623460997556e-17}\n",
      "Losses {'ner': 6.905938054751549e-15}\n",
      "Losses {'ner': 5.6645258162237916e-05}\n",
      "Losses {'ner': 5.664525816255838e-05}\n",
      "Losses {'ner': 5.6645329023453215e-05}\n",
      "Losses {'ner': 0.00023009443786814175}\n",
      "Losses {'ner': 0.00023009443906713307}\n",
      "Losses {'ner': 0.00023009443906875124}\n",
      "Losses {'ner': 0.00023009443910358378}\n",
      "Losses {'ner': 0.00023009446726209083}\n",
      "Losses {'ner': 0.0002300944672623807}\n",
      "Losses {'ner': 4.739035121698278e-12}\n",
      "Losses {'ner': 4.762133882422763e-12}\n",
      "Losses {'ner': 4.770024542579307e-12}\n",
      "Losses {'ner': 4.770031086474266e-12}\n",
      "Losses {'ner': 4.795233562443708e-12}\n",
      "Losses {'ner': 4.8190327803731834e-12}\n",
      "Losses {'ner': 8.850087263441073e-12}\n",
      "Losses {'ner': 2.3866341494800235e-11}\n",
      "Losses {'ner': 5.47136829461531e-07}\n",
      "Losses {'ner': 5.471460093890401e-07}\n",
      "Losses {'ner': 5.471460094113491e-07}\n",
      "Losses {'ner': 2.6564572221761196e-15}\n",
      "Losses {'ner': 8.647412814069633e-15}\n",
      "Losses {'ner': 7.433604165189792e-09}\n",
      "Losses {'ner': 7.434837359075356e-09}\n",
      "Losses {'ner': 7.4443974698514625e-09}\n",
      "Losses {'ner': 7.44440461637319e-09}\n",
      "Losses {'ner': 7.444405035950316e-09}\n",
      "Losses {'ner': 7.45960975831289e-09}\n",
      "Losses {'ner': 1.2241277265184816e-08}\n",
      "Losses {'ner': 1.2241278044437358e-08}\n",
      "Losses {'ner': 1.2241278133037484e-08}\n",
      "Losses {'ner': 9.89188436737418e-15}\n",
      "Losses {'ner': 5.542408739903976e-12}\n",
      "Losses {'ner': 5.550345059854316e-12}\n",
      "Losses {'ner': 2.741734151850284e-10}\n",
      "Losses {'ner': 2.7475034042017096e-10}\n",
      "Losses {'ner': 2.747799176091864e-10}\n",
      "Losses {'ner': 7.024369829778021e-10}\n",
      "Losses {'ner': 8.040329437886319e-10}\n",
      "Losses {'ner': 8.040329437949799e-10}\n",
      "Losses {'ner': 1.2852920324527667e-09}\n",
      "Losses {'ner': 1.2957971353463202e-09}\n",
      "Losses {'ner': 3.5028144274029707e-10}\n",
      "Losses {'ner': 6.875817474355747e-06}\n",
      "Losses {'ner': 6.875817507978858e-06}\n",
      "Losses {'ner': 6.880816568169113e-06}\n",
      "Losses {'ner': 6.880816569063879e-06}\n",
      "Losses {'ner': 6.880816598272959e-06}\n",
      "Losses {'ner': 6.8943081607370535e-06}\n",
      "Losses {'ner': 6.894309397557853e-06}\n",
      "Losses {'ner': 6.894408987681756e-06}\n",
      "Losses {'ner': 6.894408987682274e-06}\n",
      "Losses {'ner': 6.894409323592576e-06}\n",
      "Losses {'ner': 9.448939840212877e-14}\n",
      "Losses {'ner': 9.448940614975527e-14}\n",
      "Losses {'ner': 2.9705222061934245e-11}\n",
      "Losses {'ner': 2.971103324877773e-11}\n",
      "Losses {'ner': 2.971103337662175e-11}\n",
      "Losses {'ner': 2.9730272170601664e-11}\n",
      "Losses {'ner': 2.9730786722932525e-11}\n",
      "Losses {'ner': 3.891087782479206e-11}\n",
      "Losses {'ner': 2.7435376226388203e-09}\n",
      "Losses {'ner': 2.7435379377351792e-09}\n",
      "Losses {'ner': 2.7436242903049707e-09}\n",
      "Losses {'ner': 2.659709252841732e-07}\n",
      "Losses {'ner': 2.659709253992597e-07}\n",
      "Losses {'ner': 3.518625002233224e-07}\n",
      "Losses {'ner': 3.518677784781859e-07}\n",
      "Losses {'ner': 3.518677803214855e-07}\n",
      "Losses {'ner': 3.5186789470696686e-07}\n",
      "Losses {'ner': 3.5197669897377506e-07}\n",
      "Losses {'ner': 3.519772446127285e-07}\n",
      "Losses {'ner': 3.519772446127285e-07}\n",
      "Losses {'ner': 3.519773040395568e-07}\n",
      "Losses {'ner': 3.5197730852241555e-07}\n",
      "Losses {'ner': 2.688182521639387e-13}\n",
      "Losses {'ner': 2.7174669366686844e-13}\n",
      "Losses {'ner': 3.292056805504368e-11}\n",
      "Losses {'ner': 3.3100692013484136e-11}\n",
      "Losses {'ner': 1.0279736405887735e-10}\n",
      "Losses {'ner': 1.028178305772518e-10}\n",
      "Losses {'ner': 1.0281790806093919e-10}\n",
      "Losses {'ner': 2.9621235151652324e-10}\n",
      "Losses {'ner': 3.0461255921388955e-10}\n",
      "Losses {'ner': 3.0705169970930853e-10}\n",
      "Losses {'ner': 3.070522864378884e-10}\n",
      "Losses {'ner': 1.5515784795668624e-19}\n",
      "Losses {'ner': 4.2681441059084796e-13}\n",
      "Losses {'ner': 2.6483542872836315e-12}\n",
      "Losses {'ner': 2.6483641686940494e-12}\n",
      "Losses {'ner': 2.733826802576024e-12}\n",
      "Losses {'ner': 2.733827084722181e-12}\n",
      "Losses {'ner': 2.7338373851816645e-12}\n",
      "Losses {'ner': 3.9726917513392005e-12}\n",
      "Losses {'ner': 3.972721783059385e-12}\n",
      "Losses {'ner': 4.262365851548656e-12}\n",
      "Losses {'ner': 4.2624020519465576e-12}\n",
      "Losses {'ner': 5.4734559775719305e-11}\n",
      "Losses {'ner': 5.473642122594158e-11}\n",
      "Losses {'ner': 7.982994658568468e-10}\n",
      "Losses {'ner': 7.983437307278486e-10}\n",
      "Losses {'ner': 8.054868691495309e-10}\n",
      "Losses {'ner': 8.058266580442299e-10}\n",
      "Losses {'ner': 3.881079155142733e-09}\n",
      "Losses {'ner': 3.881079161005143e-09}\n",
      "Losses {'ner': 3.881081985470811e-09}\n",
      "Losses {'ner': 3.903748228713087e-09}\n",
      "Losses {'ner': 3.908189571406011e-09}\n",
      "Losses {'ner': 2.241332284101675e-07}\n",
      "Losses {'ner': 2.2413322844023968e-07}\n",
      "Losses {'ner': 2.241332284968851e-07}\n",
      "Losses {'ner': 2.241399363628901e-07}\n",
      "Losses {'ner': 2.522322803265844e-07}\n",
      "Losses {'ner': 2.5223228078983667e-07}\n",
      "Losses {'ner': 2.522440334456552e-07}\n",
      "Losses {'ner': 2.5224406950719187e-07}\n",
      "Losses {'ner': 2.5243884989435605e-07}\n",
      "Losses {'ner': 2.5243885005949344e-07}\n",
      "Losses {'ner': 2.5243887684112436e-07}\n",
      "Losses {'ner': 6.707099942116423e-07}\n",
      "Losses {'ner': 6.707099947970939e-07}\n",
      "Losses {'ner': 6.707132917080077e-07}\n",
      "Losses {'ner': 6.755721685652856e-07}\n",
      "Losses {'ner': 6.779050138156038e-07}\n",
      "Losses {'ner': 6.7790501443446e-07}\n",
      "Losses {'ner': 6.779050168214094e-07}\n",
      "Losses {'ner': 6.779054691342386e-07}\n",
      "Losses {'ner': 6.779182919179432e-07}\n",
      "Losses {'ner': 6.779183605248585e-07}\n",
      "Losses {'ner': 6.779185080935389e-07}\n",
      "Losses {'ner': 8.714152074466246e-09}\n",
      "Losses {'ner': 8.714155049220864e-09}\n",
      "Losses {'ner': 9.273759623774779e-09}\n",
      "Losses {'ner': 9.273759657299782e-09}\n",
      "Losses {'ner': 9.308511181452017e-09}\n",
      "Losses {'ner': 1.1528716335444854e-08}\n",
      "Losses {'ner': 1.0318769329188638e-07}\n",
      "Losses {'ner': 1.0318769331588029e-07}\n",
      "Losses {'ner': 1.0318828629152718e-07}\n",
      "Losses {'ner': 1.031882863027172e-07}\n",
      "Losses {'ner': 1.0318828667210732e-07}\n",
      "Losses {'ner': 2.97371216808154e-11}\n",
      "Losses {'ner': 2.974297141238551e-11}\n",
      "Losses {'ner': 2.974502286699243e-11}\n",
      "Losses {'ner': 2.9745138499599175e-11}\n",
      "Losses {'ner': 2.974894234200055e-11}\n",
      "Losses {'ner': 2.974894244043406e-11}\n",
      "Losses {'ner': 3.0822042782836875e-11}\n",
      "Losses {'ner': 3.0822043116551945e-11}\n",
      "Losses {'ner': 3.08330766010345e-11}\n",
      "Losses {'ner': 1.5344730423525332e-09}\n",
      "Losses {'ner': 1.5347779881162162e-09}\n",
      "Losses {'ner': 1.4637604659984108e-15}\n",
      "Losses {'ner': 2.270454571475585e-14}\n",
      "Losses {'ner': 2.3054061916163903e-14}\n",
      "Losses {'ner': 2.3443975948031314e-14}\n",
      "Losses {'ner': 2.3540068887173873e-14}\n",
      "Losses {'ner': 3.2107878436236603e-12}\n",
      "Losses {'ner': 1.909376344033553e-09}\n",
      "Losses {'ner': 1.9094651422797767e-09}\n",
      "Losses {'ner': 1.9727768266713715e-09}\n",
      "Losses {'ner': 1.972931564980789e-09}\n",
      "Losses {'ner': 1.9729515023050334e-09}\n",
      "Losses {'ner': 0.0001075677355422964}\n",
      "Losses {'ner': 0.00010756773554234725}\n",
      "Losses {'ner': 0.00010757083523068239}\n",
      "Losses {'ner': 0.00010757083523070063}\n",
      "Losses {'ner': 0.00010757083523070739}\n",
      "Losses {'ner': 0.0001075708352314396}\n",
      "Losses {'ner': 0.00010757083523144218}\n",
      "Losses {'ner': 0.00010757083523147344}\n",
      "Losses {'ner': 0.0001075708352314815}\n",
      "Losses {'ner': 0.00010757083523178775}\n",
      "Losses {'ner': 0.00010757114916969773}\n",
      "Losses {'ner': 1.9805063822087073e-13}\n",
      "Losses {'ner': 8.279351856988209e-13}\n",
      "Losses {'ner': 8.359175506102896e-13}\n",
      "Losses {'ner': 8.363820911104597e-13}\n",
      "Losses {'ner': 9.509180238478642e-10}\n",
      "Losses {'ner': 9.520570351565707e-10}\n",
      "Losses {'ner': 1.1675929440781604e-09}\n",
      "Losses {'ner': 1.167592944078337e-09}\n",
      "Losses {'ner': 1.1675929440857083e-09}\n",
      "Losses {'ner': 1.1675949583228293e-09}\n",
      "Losses {'ner': 1.1675949600820469e-09}\n",
      "Losses {'ner': 1.3971672640677125e-12}\n",
      "Losses {'ner': 1.3994276379158461e-12}\n",
      "Losses {'ner': 1.4005922504104458e-12}\n",
      "Losses {'ner': 1.400592250486291e-12}\n",
      "Losses {'ner': 1.400606083894995e-12}\n",
      "Losses {'ner': 1.4653407394350542e-11}\n",
      "Losses {'ner': 3.3959307272712842e-09}\n",
      "Losses {'ner': 3.395930745329033e-09}\n",
      "Losses {'ner': 3.395930756904341e-09}\n",
      "Losses {'ner': 3.3960073889209655e-09}\n",
      "Losses {'ner': 3.3960074051996587e-09}\n",
      "Losses {'ner': 1.0056783940433237e-23}\n",
      "Losses {'ner': 2.5471370357344287e-15}\n",
      "Losses {'ner': 2.855598961530183e-15}\n",
      "Losses {'ner': 6.96907995358234e-13}\n",
      "Losses {'ner': 6.969433726228406e-13}\n",
      "Losses {'ner': 8.122329596362223e-13}\n",
      "Losses {'ner': 0.00014389239449253083}\n",
      "Losses {'ner': 0.00014389239449267085}\n",
      "Losses {'ner': 0.0001438923946558138}\n",
      "Losses {'ner': 0.00014389239465747053}\n",
      "Losses {'ner': 0.0001438923946577016}\n",
      "Losses {'ner': 7.389008212739733e-19}\n",
      "Losses {'ner': 3.041725932755493e-13}\n",
      "Losses {'ner': 3.0501239209175813e-13}\n",
      "Losses {'ner': 3.0619595005708347e-13}\n",
      "Losses {'ner': 2.364636625163946e-12}\n",
      "Losses {'ner': 2.36464951081446e-12}\n",
      "Losses {'ner': 4.052377457513404e-12}\n",
      "Losses {'ner': 4.056423487443405e-12}\n",
      "Losses {'ner': 4.811733812703659e-11}\n",
      "Losses {'ner': 5.38244868418859e-11}\n",
      "Losses {'ner': 1.9581496220097904e-10}\n",
      "Losses {'ner': 3.677652082137136e-12}\n",
      "Losses {'ner': 2.386379118586889e-11}\n",
      "Losses {'ner': 2.3872503589418265e-11}\n",
      "Losses {'ner': 2.387250361503392e-11}\n",
      "Losses {'ner': 2.3872554197290607e-11}\n",
      "Losses {'ner': 2.3883389686984062e-11}\n",
      "Losses {'ner': 2.389163362487861e-11}\n",
      "Losses {'ner': 5.025277331758082e-11}\n",
      "Losses {'ner': 5.02537392274752e-11}\n",
      "Losses {'ner': 1.171140719840947e-10}\n",
      "Losses {'ner': 1.1711407203444162e-10}\n",
      "Losses {'ner': 2.842363880440465e-19}\n",
      "Losses {'ner': 7.562000618963769e-12}\n",
      "Losses {'ner': 7.562291761351938e-12}\n",
      "Losses {'ner': 7.562291832530604e-12}\n",
      "Losses {'ner': 7.563343669222106e-12}\n",
      "Losses {'ner': 7.563621768538894e-12}\n",
      "Losses {'ner': 7.678659880805742e-12}\n",
      "Losses {'ner': 7.678659885251719e-12}\n",
      "Losses {'ner': 7.678862289526984e-12}\n",
      "Losses {'ner': 8.586489086621045e-12}\n",
      "Losses {'ner': 8.601889065952832e-12}\n",
      "Losses {'ner': 3.960547855497164e-13}\n",
      "Losses {'ner': 3.9963693235446757e-13}\n",
      "Losses {'ner': 3.996661863431495e-13}\n",
      "Losses {'ner': 4.168930919748271e-13}\n",
      "Losses {'ner': 5.314986035733693e-12}\n",
      "Losses {'ner': 5.3150077375991e-12}\n",
      "Losses {'ner': 5.446061762702546e-12}\n",
      "Losses {'ner': 5.4462404923052896e-12}\n",
      "Losses {'ner': 5.458114212048484e-12}\n",
      "Losses {'ner': 5.458406335636397e-12}\n",
      "Losses {'ner': 5.649325123911875e-12}\n",
      "Losses {'ner': 1.8709879139764737e-13}\n",
      "Losses {'ner': 1.8710737312238475e-13}\n",
      "Losses {'ner': 1.9092437141277965e-13}\n",
      "Losses {'ner': 1.8609148290084457e-12}\n",
      "Losses {'ner': 4.068808328187231e-12}\n",
      "Losses {'ner': 6.819781618511775e-11}\n",
      "Losses {'ner': 6.826789156393611e-11}\n",
      "Losses {'ner': 6.829687264111425e-11}\n",
      "Losses {'ner': 6.94717970380779e-11}\n",
      "Losses {'ner': 6.947978170368194e-11}\n",
      "Losses {'ner': 1.9840400091116378e-07}\n",
      "Losses {'ner': 7.071094524529543e-16}\n",
      "Losses {'ner': 7.308400966456788e-16}\n",
      "Losses {'ner': 5.2420054234809127e-14}\n",
      "Losses {'ner': 5.314608535065197e-14}\n",
      "Losses {'ner': 1.9401542308046239e-10}\n",
      "Losses {'ner': 1.9402455852004773e-10}\n",
      "Losses {'ner': 1.982295719406989e-10}\n",
      "Losses {'ner': 7.085174309263965e-06}\n",
      "Losses {'ner': 7.092040535609811e-06}\n",
      "Losses {'ner': 7.092084377439284e-06}\n",
      "Losses {'ner': 7.092084386649993e-06}\n",
      "Losses {'ner': 1.5002896958841435e-10}\n",
      "Losses {'ner': 1.500289698517071e-10}\n",
      "Losses {'ner': 1.6924256931422901e-10}\n",
      "Losses {'ner': 1.8779902963804862e-10}\n",
      "Losses {'ner': 1.8924091867405863e-10}\n",
      "Losses {'ner': 1.892410872952088e-10}\n",
      "Losses {'ner': 1.8924152013007393e-10}\n",
      "Losses {'ner': 1.6190752864060027e-09}\n",
      "Losses {'ner': 1.6190762547620358e-09}\n",
      "Losses {'ner': 1.627713049069313e-09}\n",
      "Losses {'ner': 1.629052854180787e-09}\n",
      "Losses {'ner': 8.116330971797322e-13}\n",
      "Losses {'ner': 6.188896346700967e-08}\n",
      "Losses {'ner': 6.188896357939295e-08}\n",
      "Losses {'ner': 6.188896360135705e-08}\n",
      "Losses {'ner': 6.18901650155845e-08}\n",
      "Losses {'ner': 6.189016501698853e-08}\n",
      "Losses {'ner': 6.189016503450212e-08}\n",
      "Losses {'ner': 6.189017564511793e-08}\n",
      "Losses {'ner': 6.189108088118178e-08}\n",
      "Losses {'ner': 6.189108088123314e-08}\n",
      "Losses {'ner': 6.189108303321946e-08}\n",
      "Losses {'ner': 9.734269339983075e-11}\n",
      "Losses {'ner': 9.734269423984518e-11}\n",
      "Losses {'ner': 9.807868771557244e-11}\n",
      "Losses {'ner': 9.807868843520811e-11}\n",
      "Losses {'ner': 9.807869086257654e-11}\n",
      "Losses {'ner': 9.808736772862651e-11}\n",
      "Losses {'ner': 9.808748932014853e-11}\n",
      "Losses {'ner': 9.930478448255406e-09}\n",
      "Losses {'ner': 9.930505440109403e-09}\n",
      "Losses {'ner': 9.930507170308793e-09}\n",
      "Losses {'ner': 9.93050797847135e-09}\n",
      "Losses {'ner': 3.7897849502899285e-12}\n",
      "Losses {'ner': 3.789787832973195e-12}\n",
      "Losses {'ner': 3.820137616854067e-12}\n",
      "Losses {'ner': 3.8260931021187235e-12}\n",
      "Losses {'ner': 3.826094074279753e-12}\n",
      "Losses {'ner': 3.827635129800521e-12}\n",
      "Losses {'ner': 3.9144625258301276e-12}\n",
      "Losses {'ner': 4.5544888283545025e-11}\n",
      "Losses {'ner': 4.554488829815825e-11}\n",
      "Losses {'ner': 4.554488889597098e-11}\n",
      "Losses {'ner': 4.5547410603896426e-11}\n",
      "Losses {'ner': 3.1884480252027494e-11}\n",
      "Losses {'ner': 3.1884483605005154e-11}\n",
      "Losses {'ner': 3.1885838358691234e-11}\n",
      "Losses {'ner': 3.1885852036827834e-11}\n",
      "Losses {'ner': 3.188590440047931e-11}\n",
      "Losses {'ner': 3.3270129818687764e-11}\n",
      "Losses {'ner': 3.3327244903421515e-11}\n",
      "Losses {'ner': 3.3328497784706615e-11}\n",
      "Losses {'ner': 3.3328497815277905e-11}\n",
      "Losses {'ner': 3.3328498607040265e-11}\n",
      "Losses {'ner': 3.332849945323714e-11}\n",
      "Losses {'ner': 1.0990974266482555e-19}\n",
      "Losses {'ner': 1.8769783964964083e-08}\n",
      "Losses {'ner': 3.447797330516879e-08}\n",
      "Losses {'ner': 3.447797362677207e-08}\n",
      "Losses {'ner': 3.447797364579357e-08}\n",
      "Losses {'ner': 3.4477973659405787e-08}\n",
      "Losses {'ner': 3.4478008035956154e-08}\n",
      "Losses {'ner': 3.447873222598219e-08}\n",
      "Losses {'ner': 3.447873224708475e-08}\n",
      "Losses {'ner': 3.447873252152932e-08}\n",
      "Losses {'ner': 3.447873252183832e-08}\n",
      "Losses {'ner': 8.228657096423184e-21}\n",
      "Losses {'ner': 1.2255284169630499e-14}\n",
      "Losses {'ner': 1.2693066503107527e-14}\n",
      "Losses {'ner': 9.371542077152578e-10}\n",
      "Losses {'ner': 9.692708194261656e-10}\n",
      "Losses {'ner': 9.692859549198128e-10}\n",
      "Losses {'ner': 9.692882236006758e-10}\n",
      "Losses {'ner': 9.69804420862567e-10}\n",
      "Losses {'ner': 9.760677215741831e-10}\n",
      "Losses {'ner': 1.4337397896720321e-09}\n",
      "Losses {'ner': 8.788030631617826e-09}\n",
      "Losses {'ner': 7.281831868435421e-18}\n",
      "Losses {'ner': 1.1250614363575637e-10}\n",
      "Losses {'ner': 1.1255512846239686e-10}\n",
      "Losses {'ner': 1.1285210243042022e-10}\n",
      "Losses {'ner': 1.1285497054831585e-10}\n",
      "Losses {'ner': 1.1533623768397086e-10}\n",
      "Losses {'ner': 1.1533629490092156e-10}\n",
      "Losses {'ner': 1.1533638304085829e-10}\n",
      "Losses {'ner': 1.1542353387573878e-10}\n",
      "Losses {'ner': 7.987400196982348e-08}\n",
      "Losses {'ner': 7.98740042483281e-08}\n",
      "Losses {'ner': 3.552646224821498e-21}\n",
      "Losses {'ner': 7.510156051443187e-18}\n",
      "Losses {'ner': 3.5198882701937717e-16}\n",
      "Losses {'ner': 6.818381084265931e-15}\n",
      "Losses {'ner': 8.084964174734893e-13}\n",
      "Losses {'ner': 8.084966819927576e-13}\n",
      "Losses {'ner': 8.091558740251658e-13}\n",
      "Losses {'ner': 8.091559058122146e-13}\n",
      "Losses {'ner': 1.4092128955510879e-09}\n",
      "Losses {'ner': 1.409238319734295e-09}\n",
      "Losses {'ner': 1.4092391251966863e-09}\n",
      "Losses {'ner': 1.143086292792182e-09}\n",
      "Losses {'ner': 4.877681162751851e-08}\n",
      "Losses {'ner': 4.8777386995463366e-08}\n",
      "Losses {'ner': 4.8777387000423015e-08}\n",
      "Losses {'ner': 4.87773870062689e-08}\n",
      "Losses {'ner': 4.8777387006280996e-08}\n",
      "Losses {'ner': 4.8777391821443205e-08}\n",
      "Losses {'ner': 4.882300906794865e-08}\n",
      "Losses {'ner': 4.882365253736994e-08}\n",
      "Losses {'ner': 4.8823653036036805e-08}\n",
      "Losses {'ner': 4.882365303622579e-08}\n",
      "Losses {'ner': 5.073809101153169e-12}\n",
      "Losses {'ner': 8.141722649842051e-09}\n",
      "Losses {'ner': 8.141756537973474e-09}\n",
      "Losses {'ner': 8.142146256608351e-09}\n",
      "Losses {'ner': 8.142153382405488e-09}\n",
      "Losses {'ner': 8.14471444913284e-09}\n",
      "Losses {'ner': 8.21764884531515e-09}\n",
      "Losses {'ner': 8.217649218285033e-09}\n",
      "Losses {'ner': 8.217649251746694e-09}\n",
      "Losses {'ner': 8.21770529482063e-09}\n",
      "Losses {'ner': 8.217706185191e-09}\n",
      "Losses {'ner': 1.0590200661436428e-14}\n",
      "Losses {'ner': 1.494816105672705e-14}\n",
      "Losses {'ner': 1.4949160006790908e-14}\n",
      "Losses {'ner': 3.390382045448819e-09}\n",
      "Losses {'ner': 3.3903894439676896e-09}\n",
      "Losses {'ner': 3.3904216200812508e-09}\n",
      "Losses {'ner': 3.3905285098586283e-09}\n",
      "Losses {'ner': 3.3905285102811215e-09}\n",
      "Losses {'ner': 3.3905285102951666e-09}\n",
      "Losses {'ner': 3.3905285164784133e-09}\n",
      "Losses {'ner': 3.3905440727951697e-09}\n",
      "Losses {'ner': 9.43360360377258e-19}\n",
      "Losses {'ner': 3.068388665406267e-12}\n",
      "Losses {'ner': 3.0684640385367275e-12}\n",
      "Losses {'ner': 3.1125671625791285e-12}\n",
      "Losses {'ner': 3.113705723393766e-12}\n",
      "Losses {'ner': 3.5536472422991803e-12}\n",
      "Losses {'ner': 3.553784897434725e-12}\n",
      "Losses {'ner': 3.643775901778034e-12}\n",
      "Losses {'ner': 3.717151641148075e-12}\n",
      "Losses {'ner': 3.7171616512812454e-12}\n",
      "Losses {'ner': 3.717171335556231e-12}\n",
      "Losses {'ner': 2.2625459919085215e-15}\n",
      "Losses {'ner': 1.2968924350358369e-14}\n",
      "Losses {'ner': 2.3542561001615158e-12}\n",
      "Losses {'ner': 2.3563315415875518e-12}\n",
      "Losses {'ner': 6.4489561148556365e-12}\n",
      "Losses {'ner': 7.276608077102477e-12}\n",
      "Losses {'ner': 7.276622518748212e-12}\n",
      "Losses {'ner': 7.279177685720148e-12}\n",
      "Losses {'ner': 9.34389519384945e-12}\n",
      "Losses {'ner': 2.7159670347817664e-09}\n",
      "Losses {'ner': 2.7203289774465173e-09}\n",
      "Losses {'ner': 4.578038606698268e-14}\n",
      "Losses {'ner': 5.631242023738772e-13}\n",
      "Losses {'ner': 5.634435753473863e-13}\n",
      "Losses {'ner': 9.792101683878148e-13}\n",
      "Losses {'ner': 9.792103037757677e-13}\n",
      "Losses {'ner': 2.1573684176772944e-12}\n",
      "Losses {'ner': 2.1573684270890523e-12}\n",
      "Losses {'ner': 2.170545521217743e-12}\n",
      "Losses {'ner': 3.209727933513207e-12}\n",
      "Losses {'ner': 3.209727933570199e-12}\n",
      "Losses {'ner': 4.06449343905124e-10}\n",
      "Losses {'ner': 1.03008417895256e-07}\n",
      "Losses {'ner': 1.0300846548792172e-07}\n",
      "Losses {'ner': 1.0300846548793793e-07}\n",
      "Losses {'ner': 1.1168386117386211e-07}\n",
      "Losses {'ner': 1.1168386253045311e-07}\n",
      "Losses {'ner': 1.1168386253048014e-07}\n",
      "Losses {'ner': 1.1168386271078133e-07}\n",
      "Losses {'ner': 1.1168386505827038e-07}\n",
      "Losses {'ner': 1.1168390980509739e-07}\n",
      "Losses {'ner': 1.1168390980510897e-07}\n",
      "Losses {'ner': 1.1168390980513426e-07}\n",
      "Losses {'ner': 1.276769667611287e-17}\n",
      "Losses {'ner': 1.7984226296945677e-08}\n",
      "Losses {'ner': 1.7984925224920055e-08}\n",
      "Losses {'ner': 1.7985503305584556e-08}\n",
      "Losses {'ner': 1.798551169073983e-08}\n",
      "Losses {'ner': 1.7985511821669458e-08}\n",
      "Losses {'ner': 1.7985515938767847e-08}\n",
      "Losses {'ner': 1.799145225140725e-08}\n",
      "Losses {'ner': 1.799200342750519e-08}\n",
      "Losses {'ner': 1.7992345881268696e-08}\n",
      "Losses {'ner': 1.7992345898955032e-08}\n",
      "Losses {'ner': 8.10769925703165e-16}\n",
      "Losses {'ner': 7.627709078565332e-13}\n",
      "Losses {'ner': 7.814411987129498e-13}\n",
      "Losses {'ner': 7.855759292743158e-13}\n",
      "Losses {'ner': 3.3267228713460256e-11}\n",
      "Losses {'ner': 2.391148732058305e-10}\n",
      "Losses {'ner': 2.3911488254359536e-10}\n",
      "Losses {'ner': 2.391148827869695e-10}\n",
      "Losses {'ner': 2.4010448001865564e-10}\n",
      "Losses {'ner': 2.4873209648149945e-10}\n",
      "Losses {'ner': 2.497796140670191e-10}\n",
      "Losses {'ner': 6.949213759353837e-16}\n",
      "Losses {'ner': 7.000732207627912e-16}\n",
      "Losses {'ner': 7.000901985559493e-16}\n",
      "Losses {'ner': 7.001618787266665e-16}\n",
      "Losses {'ner': 2.318035974253553e-11}\n",
      "Losses {'ner': 2.3427391169814063e-11}\n",
      "Losses {'ner': 2.3459479881999596e-11}\n",
      "Losses {'ner': 2.3460646221168735e-11}\n",
      "Losses {'ner': 2.3461073780049203e-11}\n",
      "Losses {'ner': 2.346107423470737e-11}\n",
      "Losses {'ner': 2.3462374886291937e-11}\n",
      "Losses {'ner': 1.156395539290533e-10}\n",
      "Losses {'ner': 1.156395543759158e-10}\n",
      "Losses {'ner': 1.1852149993977278e-10}\n",
      "Losses {'ner': 3.5230566535275245e-08}\n",
      "Losses {'ner': 3.5230566535778025e-08}\n",
      "Losses {'ner': 3.523056662694577e-08}\n",
      "Losses {'ner': 3.5256773992017797e-08}\n",
      "Losses {'ner': 3.5256774037079466e-08}\n",
      "Losses {'ner': 3.525677422626991e-08}\n",
      "Losses {'ner': 3.527952374129349e-08}\n",
      "Losses {'ner': 3.527952374281524e-08}\n",
      "Losses {'ner': 4.066172743705702e-14}\n",
      "Losses {'ner': 4.234711568195356e-14}\n",
      "Losses {'ner': 4.2361339411443924e-14}\n",
      "Losses {'ner': 6.844852802814404e-13}\n",
      "Losses {'ner': 6.920740026201996e-13}\n",
      "Losses {'ner': 6.951305350756198e-13}\n",
      "Losses {'ner': 2.196927394128775e-10}\n",
      "Losses {'ner': 2.7506183786705017e-10}\n",
      "Losses {'ner': 2.7506183786706046e-10}\n",
      "Losses {'ner': 2.7506193768651457e-10}\n",
      "Losses {'ner': 2.7506239105547665e-10}\n"
     ]
    }
   ],
   "source": [
    "# Importing requirements\n",
    "from spacy.util import minibatch, compounding\n",
    "import random\n",
    "\n",
    "# Begin training by disabling other pipeline components\n",
    "with nlp.disable_pipes(*other_pipes) :\n",
    "\n",
    "    sizes = compounding(1.0, 4.0, 1.001)\n",
    "    # Training for 30 iterations     \n",
    "    for itn in range(30):\n",
    "    # shuffle examples before training\n",
    "        random.shuffle(examples)\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(examples, size=sizes)\n",
    "        losses = {}\n",
    "        for batch in batches:\n",
    "            # Calling update() over the iteration\n",
    "            nlp.update(batch, sgd=optimizer, drop=0.35, losses=losses)\n",
    "            print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16cf4465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities in 'Chocolate soufflé is extremely famous french cuisine'\n",
      "Entities in 'Burgers are the most commonly consumed fastfood'\n",
      "Burgers\n",
      "{'entities': [(0, 7, 'FOOD')]}\n",
      "Entities in 'Lasagna is another classic of Italy'\n",
      "Lasagna\n",
      "{'entities': [(0, 7, 'FOOD')]}\n",
      "Entities in 'Shrimps are famous in China too'\n",
      "Shrimps\n",
      "{'entities': [(0, 7, 'FOOD')]}\n"
     ]
    }
   ],
   "source": [
    "# Testing the NER\n",
    "\n",
    "for t in test:\n",
    "    test_text = t[0]\n",
    "    doc = nlp(test_text)\n",
    "    print(\"Entities in '%s'\" % test_text)\n",
    "    for ent in doc.ents:\n",
    "        print(ent)\n",
    "        print(t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a3812b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2c8a4eb2d113>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmatcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhraseMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmatched_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Collect data of matched sentences to be visualized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MetabolysmAnalysisAPI/venv/lib/python3.8/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, disable, exclude, config)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \"\"\"\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MetabolysmAnalysisAPI/venv/lib/python3.8/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "matched_sents = []  # Collect data of matched sentences to be visualized\n",
    "terms = [\"Barack Obama\", \"Angela Merkel\", \"Washington, D.C.\"]\n",
    "\n",
    "def collect_sents(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    span = doc[start:end]  # Matched span\n",
    "    sent = span.sent  # Sentence containing matched span\n",
    "    # Append mock entity for match in displaCy style to matched_sents\n",
    "    # get the match span by ofsetting the start and end of the span with the\n",
    "    # start and end of the sentence in the doc\n",
    "    match_ents = [{\n",
    "        \"start\": span.start_char - sent.start_char,\n",
    "        \"end\": span.end_char - sent.start_char,\n",
    "        \"label\": \"MATCH\",\n",
    "    }]\n",
    "    matched_sents.append({\"text\": sent.text, \"ents\": match_ents})\n",
    "\n",
    "patterns = [nlp.make_doc(text) for text in terms]\n",
    "matcher.add(\"TerminologyList\", patterns, on_match=collect_sents)\n",
    "\n",
    "doc = nlp(\"German Chancellor Angela Merkel and US President Barack Obama \"\n",
    "          \"converse in the Oval Office inside the White House in Washington, D.C.\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Serve visualization of sentences containing match with displaCy\n",
    "# set manual=True to make displaCy render straight from a dictionary\n",
    "# (if you're not running the code within a Jupyer environment, you can\n",
    "# use displacy.serve instead)\n",
    "displacy.render(matched_sents, style=\"ent\", manual=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
